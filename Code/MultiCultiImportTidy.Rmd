---
title: "Microbial Growth Analyses - MultiCulti & Cell Counts"
author:
- Heather MacTavish^1^
- Douglas A. Campbell^1^*
- Mireille Savoie^1^
- Laurel Genge^1^
- Carlie Barnhill^1^
- Max Berthold^1^

date: "`r format(Sys.Date())`"
output:
  rmdformats::readthedown:
    df_print: paged
    code_folding: hide
    self_contained: true
    keep_md: yes
    fig_caption: yes
---
```{css, echo=FALSE}
p.caption {
  font-size: 18px;
}
```

# Affiliations {-}
^1^Mount Allison University, New Brunswick, Canada  

*corresponding author 

# Acknowledgement {-}
This R markdown file is adapted from the `Import_MCData` file created by Laurel Genge, Carlie Barnhill, Max Berthold, Mireille Savoie, and Douglas A. Campbell [@genge_import_mcdata_2024] for the Plastic Degradation project by Heather MacTavish, Andrew Forrest, and Yvanna Tchatchoua in BIOL3111.

Dr. Campbell was supported by the Canada Research Chairs.


# Overview

This .Rmd Rworkbook imports data in simple .csv long form exported from PSI Multicultivators based upon project specific values for variables set by the user.

It imports .csv file(s) with cell count data taken in parallel.

It tidies and organizes the data. It uses a pivot_wider and interpolation approach to get the Actinic_par and OD values in line rowwise. This requires careful 'arrange' of the rows. It imports a metadata catalog (Data/RawData/"CultureCatalog.Rds") and merges the metadata with the imported data based
upon shared values for the variables 'MC', 'Tube', and 'Filename' which should unambiguously identify a given growth trajectory measured at OD680 or OD720. 

It generates preliminary data plots. It filters the data for outliers by screening out values distant from the moving average of a window in the stream; this requires careful 'arrange' of the rows so sequential rows represent sequential time steps [@genge_import_mcdata_2024].

This works because the OD680 & OD720 data are only episodically, but widely, aberrant when a bubble interrupts the measurement, and if the Multicultivator is running properly these bubble aberration events are rare [@genge_import_mcdata_2024].


# Introduction 
The PSI Multicultivator is used to grow 8 x 80 ml of phytoplankton culture under a common temperature regime, with individual control of bubbling, light level, light spectral quality and photoperiod for each of the 8 culture tubes.


# Materials and Methods

## Data Handling

Formatted display of content from .md file on GitHub site.
Upon knitr figures will be saved to 'Figs/'
```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, error = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.path='Figs/')
```

### Load Libraries
Libraries add functionality to base R
```{r load libraries, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(broom)
library(zoo)
library(minpack.lm)
library(kableExtra)
```

This report was generated in `R version 4.3.2` [@r_core_team_r_2023], with the packages: `tidyverse`[@wickham_welcome_2019], `lubridate` [@grolemund_dates_2011], `knitr` [@xie_knitr_2023; @xie_dynamic_2015; @stodden_knitr_2014], `broom` [@robinson_broom_2024],`data.table` [@barrett_datatable_2024], and `zoo` [@zeileis_zoo_2005].

```{r set project variables}
Project <- "B2201"

# Multicultivator data files are too large to upload in a single .zip  .zipped folders can be uploaded. 

DataIn <- file.path("..", "Data", "RawData")

DataOut <- file.path("..","Data", "ProcessedData")

# number of rows to skip upon read csv
Skip <- 20
MetaLines <- 17
```

# Read data in for work in R
```{r raw data files}

#List files in data folder
list.files(DataIn)
```


```{r cell count data}
CellCountData <- read_csv(file = file.path(DataIn, "CellCountsMaster.csv")) |>
  filter(!is.na(REP_C_num)) #spurious rows imported

CellCountData

unique(CellCountData$REP_C_num)  #extensive incorrect data coding

CellCountData <- CellCountData |>
  filter(REP_C_num != "CHLORELLA", 
         REP_C_num != "C-HIGH3",
         REP_C_num != "c-LOW-1",
         REP_C_num != "S-HIGH-2",
         REP_C_num != "C-LOW-4",
         REP_C_num != "C-HIGH-4",
         REP_C_num != "C-HIGH-5"
         )  # remove incorrect data entry

unique(CellCountData$REP_C_num)
```

```{r set TargetFile and read csv, warning = FALSE, message = FALSE}

TargetFile <- "20250128_B2201_MCMIX004_123_0.csv"
TubeLabels = 123
Light = 90

TargetData <- read_csv(file = file.path(DataIn, TargetFile), skip = Skip, 
                        id = "Path", 
                        col_names = c("key", "time", 
                                      "abs-time", "value")
                       )

TargetFileName <- str_remove(string = TargetFile, pattern = ".csv")

TargetData <- TargetData |>
  mutate(Filename = TargetFileName)

```


```{r read metadata header rows}
MetaData <- read_csv(file = file.path(DataIn, TargetFile), n_max = MetaLines) |>
  filter(NAME != "GROUP_TYPE",
         NAME != "GROUP_NAME",
         NAME != "GROUP_ID",
         NAME != "PLANNED_DURATION",
         NAME != "PLANNED_DURATION_SEC",
         NAME != "INOCULUM",
         NAME != "key",
         NAME != "GASSING",
         NAME != "TERMINATION")

```


```{r tidy MultiDataTarget}
#filter superfluous rows to simplify later pivot
TargetData <- TargetData %>%
  filter(str_detect(key, "od-720|od-680|actinic-lights.light")) |>
  dplyr::select(key, time, `abs-time`, value, Filename) |>
  mutate(abs_time = lubridate::dmy_hms(as.character(`abs-time`)),
         Tube = as.numeric(str_extract(key, "[:digit:]"))
         ) |>
  dplyr::select(-`abs-time`)


#extract StartHour dynamically from first row of abs_time and display for cross check
StartHour <- as.numeric(format(TargetData$abs_time[1], format = "%H"))

StartDate <- TargetData$abs_time[1]

#Generate ToD as mod 24 of time + StartHour
TargetData <- TargetData %>%
  mutate(ToD = (time + StartHour) %% 24,
         Day = round((time/24), digits = 0))
#had trouble extracting 'Day' from abs_time, only got 3 unique values
  
```

Data validation plot
```{r data plot}
TargetData |>
  ggplot() +
  geom_point(aes(x = abs_time, y = value)) +
  facet_grid(cols = vars(Tube))
```


# Generate par_ue column with rows aligned with OD measures

# Pivot_wider to get actinic-lights data aligned with relevant sensor data. Need to include arrange(Filename, time, Tube) to keep things aligned! Need to group_by and/or reorder rows appropriately; Be Careful [

```{r pivot_wider}
#possible issue with data structure; there are multiple values for some of the rows of actinic light columns, so the column becomes a list.
#Can add  values_fn = 
#to arbitrarily take the max or min etc. element of the list; but there might be a wider problem here when importing multiple files

TargetDataWide <- TargetData %>%
  pivot_wider(names_from = key, values_from = value, values_fn = list(value = max)) %>%
  arrange(Filename, Tube, time)

```

Actinic light values do not align time wise with OD measures 

Interpolate NA in actinic light columns from last observation, arrange by MC & Tube Then generate Actinic_par summary column. If multiple lights are activated, this chunk will give the summed par of all different colours for the tube. If a single actinic light is activated per tube, this gives the par for that tube. Filter rows where !is.na(Actinic_par) to check for incorrect row sums [@genge_import_mcdata_2024].

Interpolation for Sine is not necessarily appropriate interpolation for Square photoregime; issues with propagating last Actinic_par of afternoon through evening, or back-casting first Actinic_par of morning [@genge_import_mcdata_2024].

Small glitching adding actinic_light values for tubes where actinic_light column should be 0; issue with interpolation we think [@genge_import_mcdata_2024].

```{r interpolate and summarize actinic_par by tube MCMIX004}
#http://publish.illinois.edu/spencer-guerrero/2014/12/11/2-dealing-with-missing-data-in-r-omit-approx-or-spline-part-1/
#https://dplyr.tidyverse.org/dev/articles/colwise.html
#Interpolation causes problems with final rows that repeat last value.

interpolate <- function(x){zoo::na.locf(x, na.rm = FALSE, fromLast = FALSE, type = "l", maxgap = Inf)}

#possible problem with actinic_par for MC data b/c actinic-lights.light1 = NA generates actinic_par of 0 b/c in rowSums na.rm = TRUE, which treats NA as 0.
#possibly not a big problem but watch for bugs
#na.rm = FALSE fails to run
TargetDataWide <- TargetDataWide %>%
  group_by(Tube) %>%
  arrange(Filename, Tube, time) %>%
  mutate(across(.cols = starts_with("actinic-lights.light"), .fns = interpolate)) %>%
  ungroup() %>%
  mutate(Actinic_par = rowSums(.[grep("actinic-lights.light", names(.))], na.rm = TRUE)) %>%
  filter(!is.na(Actinic_par)) %>%
   dplyr::select(!contains("actinic-lights.light"))
```

Now that Actinic_par is aligned with each row, coalesce od-sensors-X.od-720 and od-sensors-X.od-680 into 2 columns, b/c 'Tube'is already a column, so no need to identify tube X in od-sensors-X.od-680 columns. This might cause problems later matching OD measures to actinic light colours 

```{r consolidate OD}
TargetDataWide <- TargetDataWide  %>%
   mutate(OD680 = rowSums(.[grep("od-680", names(.))], na.rm = TRUE),
          OD720 = rowSums(.[grep("od-720", names(.))], na.rm = TRUE)) %>%
   dplyr::select(!contains("od-sensors"))
```

# Filter out rows where OD680 = 0 b/c time is measure more often than OD.
```{r filter OD}
TargetDataWideFilter <- TargetDataWide |>
  filter(OD680 != 0)
```


```{r data validation plot}
TargetDataWideFilter %>% 
  ggplot() + 
  geom_point(aes(x = time, 
             y = OD680), size = 1, alpha = 0.5) + 
  labs( title = "680 nm Optical Density Readings of Chlorella Cultures", 
        subtitle = paste(Light, " umol photons m-2 s-1"), 
        x = "Elapsed Time (hours)", 
        y = "Optical Density (OD at 680 nm)", 
       ) + 
  facet_grid(cols = vars(Tube)) + 
  # scale_x_continuous(breaks = seq(0, 800, by = 48)) + 
  # scale_y_continuous(limits = c(0, 0.1)) +
  theme_bw() + 
  theme( axis.text.x = element_text(size = 9, angle = 90), 
         strip.text = element_text(size = 10, face = "bold"),
         plot.caption = element_text(size = 8, hjust = 0),
         plot.margin = margin(10, 10, 50, 10) )
```

# Filter OD outliers
Rewrite with Time Series tools?? Filtering messes up unless - values
removed b/c of divisions

Experiment end times are tube specific taken from metacatalog
StartDate taken from first abs_time point from MC software

MAD is median absolute deviation. Used median as opposed to mean to filter anomalous OD values due to affects of bubbling interference because determining outliers from the mean in a given window with many outliers were not detected since deviations from the mean were low. 
```{r filter bad OD and data points after experiment end time }

#first 5 h sampling every 5 min; filter out
TargetDataWideFilter <- TargetDataWideFilter |>
  filter(time >= 5)

#moving average screen
MovAvgScreen <- 5 # 6
MovAvgWindow <- 7 # 20

TargetDataWideFilter <- TargetDataWideFilter %>%
  group_by(Tube) %>%
  arrange(Filename, Tube, time) %>%
  # mutate(ExpEndHour = (difftime(ExpEndDate, StartDate, units = "hours"))) %>%
  #  mutate(TimeFlag = case_when(time >= ExpEndHour  ~ 1, 
  #                             time < ExpEndHour ~ 0)) %>%
  mutate(MovMedian680 = rollapply(OD680, MovAvgWindow, median, fill = "extend",  align = "left"),
         MovMedian720 = rollapply(OD720, MovAvgWindow, median, fill = "extend",  align = "left"),
         MovMAD680 = rollapply(OD680, MovAvgWindow, mad, fill = "extend",  align = "left"), 
         MovMAD720 = rollapply(OD720, MovAvgWindow, mad, fill = "extend",  align = "left"), 
         IsMovMAD680Outlier = if_else(OD680 > MovMedian680 + (MovMAD680 * MovAvgScreen) | OD680 < MovMedian680 - (MovMAD680 * MovAvgScreen), 1,0),
         IsMovMAD720Outlier = if_else(OD720 > MovMedian720 + (MovMAD720 * MovAvgScreen) | OD720 < MovMedian720 - (MovMAD720 * MovAvgScreen), 1,0))


TargetDataWideFilter <- TargetDataWideFilter %>%
  filter(
    !is.na(IsMovMAD680Outlier),
    !is.na(IsMovMAD720Outlier),
    IsMovMAD680Outlier == 0,
    IsMovMAD720Outlier == 0
         ) |>
  filter(OD680 <= 0.5, # hack fix to deal with large excursion
         OD720 <= 0.5,
         OD680 >= 0,
         OD720 >= 0)  


```

# check to confirm filter and ensure there are data points for all 8 tubes. If there is a missing tube, confirm that data was filtered out because OD680 and/or OD720 <0. If this is the case run the chunk "Add positive OD dummy points" above and rerun subsequent chunks.
```{r filterdataplot}

TargetDataWideFilter %>%
  ggplot() +
  geom_point(aes(x = time, y = OD680), size = 0.15, colour = "darkgreen") +
  geom_point(aes(x = time, y = OD720), size = 0.15, colour = "black") +
 facet_grid(cols = vars(as.factor(Tube))) +
  theme_bw()

```

# Remove outlier filtering columns to simplify
```{r remove outlier filtering variables}
TargetDataWideFilter <- TargetDataWideFilter |>
  select(-c("MovMedian680", "MovMedian720", "MovMAD680", "MovMAD720", "IsMovMAD680Outlier", "IsMovMAD720Outlier"))
```

# Fits of Data
Create R function for logistic equation.
```{r fitting functions, message = FALSE}
#define a logistic equation as a function.
#x will be taken from 'time' when we run the fit.
logistic_eqn <- function(x, Lmax, Lmu, Lintercept){(Lmax*Lintercept*exp(Lmu*x))/(Lmax + (Lintercept*(exp(Lmu*x)-1)))}

```


```{r nested regressions }

#nest must include all variables that have more than one value for a given tube nest.
#filtering to remove negative lognorm data only upon transition to ProcessDataNestGrowth and fitting; could do earlier?
  # filter(lognormdeltaOD >= 0) %>%
  # filter(lognormOD720 >= 0) %>%

#fits fail for tubes 5, 6, 7; too much scatter, too many gaps
TargetDataNest  <- TargetDataWideFilter  |>
  nest(tubedata = c(time, abs_time, ToD, Day, Actinic_par, OD680, OD720))


TargetDataGrowth <- TargetDataNest %>%
  mutate(OD720_logistic = map(tubedata, possibly(~nlsLM(OD720 ~ logistic_eqn(x = time, Lmax, Lmu, Lintercept),
                            data = .x,
                            start = list(Lmax = max(.$OD720, na.rm = TRUE),  
                                         Lmu = (log(max(.$OD720, na.rm = TRUE)) - log(min(.$OD720, na.rm = TRUE)))/max(.$time),
                                         Lintercept = min(.$OD720, na.rm = TRUE)),
                            control = list(maxiter = 500)), otherwise = NULL)),
         OD720_logistic_tidied =  map(OD720_logistic, possibly(tidy, otherwise = NULL)),
         OD720_logistic_param = map(OD720_logistic,possibly(glance, otherwise = NULL)),
         OD720_logistic_predict = map(OD720_logistic, possibly(augment, otherwise = NULL))
  )  %>%
  mutate(OD720_TimetoMax = map(.x = OD720_logistic_predict, possibly(~.$time[which.max(.$`.fitted`)], otherwise = NULL))  
         ) %>% 
  mutate(OD720_TimetoMax = as.numeric(ifelse(OD720_TimetoMax == "NULL" , NA, OD720_TimetoMax))
         ) |>
   mutate(OD680_logistic = map(tubedata, possibly(~nlsLM(OD680 ~ logistic_eqn(x = time, Lmax, Lmu, Lintercept),
                            data = .x,
                            start = list(Lmax = max(.$OD680, na.rm = TRUE),  
                                         Lmu = (log(max(.$OD680, na.rm = TRUE)) - log(min(.$OD720, na.rm = TRUE)))/max(.$time),
                                         Lintercept = min(.$OD680, na.rm = TRUE)),
                            control = list(maxiter = 500)), otherwise = NULL)),
         OD680_logistic_tidied =  map(OD680_logistic, possibly(tidy, otherwise = NULL)),
         OD680_logistic_param = map(OD680_logistic,possibly(glance, otherwise = NULL)),
         OD680_logistic_predict = map(OD680_logistic, possibly(augment, otherwise = NULL))
  )  %>%
  mutate(OD680_TimetoMax = map(.x = OD680_logistic_predict, possibly(~.$time[which.max(.$`.fitted`)], otherwise = NULL))  
         ) %>% 
  mutate(OD680_TimetoMax = as.numeric(ifelse(OD680_TimetoMax == "NULL" , NA, OD680_TimetoMax))
         )

```

# Plot multiculti data with logistic curve fits
```{r logistic plots}
TargetDataGrowth %>%
  unnest(OD680_logistic_predict) |>
  ggplot() +
  geom_point(aes(x = time, y = OD680), size = 0.15) +
  geom_line(aes(x = time, y = `.fitted`), colour = "darkgreen") +
  geom_point(aes(x = time, y = `.resid`), colour = "red", size = 0.15) +
 facet_grid(cols = vars(as.factor(Tube))) +
  theme_bw()

TargetDataGrowth %>%
  unnest(OD720_logistic_predict) |>
  ggplot() +
  geom_point(aes(x = time, y = OD720), size = 0.15) +
  geom_line(aes(x = time, y = `.fitted`), colour = "black") +
  geom_point(aes(x = time, y = `.resid`), colour = "red", size = 0.15) +
 facet_grid(cols = vars(as.factor(Tube))) +
  theme_bw()
```

# Plot Cell Count Data
```{r generate E_hours}
CellCountData <- CellCountData |>
  unite(DateTime, Date_YYYYMMDD:TIME_HHMM, sep = " ") |>
  mutate(DateTime = lubridate::mdy_hm(DateTime)) |>
  mutate(E_hours = as.numeric(DateTime - min(DateTime, na.rm = TRUE))) |>
  mutate(E_hours = (E_hours - min(E_hours, na.rm = TRUE))/3600)
```


```{r cell count plot}
CellCountData |>
  ggplot() +
  geom_point(aes(x = E_hours, y = CELLS_ML )) +
  facet_grid(cols = vars(REP_C_num)) +
  theme_bw()

CellCountData |>
  ggplot() +
  geom_point(aes(x = E_hours, y = log(CELLS_ML))) +
  facet_grid(cols = vars(REP_C_num)) +
  theme_bw()


```

```{r nest cell count data}
CellCountNest  <- CellCountData  |>
  nest(CountData = -c(LIGHT,GENUS))

```


```{r}

CellGrowth <- CellCountNest %>%
  mutate(Cell_logistic = map(CountData, possibly(~nlsLM(CELLS_ML ~ logistic_eqn(x = E_hours, Lmax, Lmu, Lintercept),
                            data = .x,
                            start = list(Lmax = max(.$CELLS_ML, na.rm = TRUE),  
                                         Lmu = (log(max(.$CELLS_ML, na.rm = TRUE)) - log(min(.$CELLS_ML, na.rm = TRUE)))/max(.$time),
                                         Lintercept = min(.$CELLS_ML, na.rm = TRUE)),
                            control = list(maxiter = 500)), otherwise = NULL)
                            ),
         Cell_logistic_tidied =  map(Cell_logistic, possibly(tidy, otherwise = NULL)),
         Cell_logistic_param = map(Cell_logistic,possibly(glance, otherwise = NULL)),
         Cell_logistic_predict = map(Cell_logistic, possibly(augment, otherwise = NULL))
  )  %>%
  mutate(Cell_TimetoMax = map(.x = Cell_logistic_predict, possibly(~.$time[which.max(.$`.fitted`)], otherwise = NULL))  
         ) %>% 
  mutate(Cell_TimetoMax = as.numeric(ifelse(Cell_TimetoMax == "NULL" , NA, OD720_TimetoMax))
         ) 

```

# plot cell count with logistic
```{r cell count logistic plot}
CellGrowth %>%
  unnest(Cell_logistic_predict) |>
  ggplot() +
  geom_point(aes(x = E_hours, y = CELLS_ML), size = 0.15) +
  geom_line(aes(x = E_hours, y = `.fitted`), colour = "darkgreen") +
  geom_point(aes(x = E_hours, y = `.resid`), colour = "red", size = 0.15) +
 facet_grid(cols = vars(as.factor(LIGHT))) +
  theme_bw()
```


# MultiCulti Fit parameters
```{r multiculti fit param}
kable(TargetDataGrowth |>
  select(c(Tube, OD680_logistic_tidied, OD720_logistic_tidied)) |>
unnest(cols = c(OD680_logistic_tidied, OD720_logistic_tidied), names_sep = "_") |>
  select(-c(OD680_logistic_tidied_statistic, OD720_logistic_tidied_statistic, OD720_logistic_tidied_term)) |>
  rename_with(~str_remove(.x, "tidied_")) |>
  rename(Term = OD680_logistic_term),
digits = 3
)
```

# Cell Count Fit parameters
```{r cell count fit param}
kable(CellGrowth |>
  select(c(LIGHT, Cell_logistic_tidied)) |>
  unnest(cols = c(Cell_logistic_tidied), names_sep = "_") |>
  select(-c(Cell_logistic_tidied_statistic)) |>
  rename_with(~str_remove(.x, "tidied_")) |>
  rename(Term = Cell_logistic_term),
digits = 3
)

```


Export data to .csv
```{r write to csv}

TargetDataPivot <- TargetDataWideFilter |>
  pivot_wider(names_from = Tube, values_from = c(OD680, OD720)) |>
  na.omit()
                
write_csv(TargetDataPivot, file = file.path(DataOut, paste("MultiCultiTubes", TubeLabels, ".csv", sep = ""))
)

write_csv(MetaData, file = file.path(DataOut, paste("MultiCultiMetaData", ".csv", sep = ""))
)

write_csv(CellCountData, file = file.path(DataOut, paste("CellCountData", ".csv", sep = ""))
)

```

